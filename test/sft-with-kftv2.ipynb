{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23311f4-370f-43f6-9792-0b38a1aa483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "# !pip install --no-deps --upgrade --force-reinstall --no-cache-dir \"git+https://github.com/briangallagher/sdk@training-hub\"\n",
    "# !pip install --upgrade --force-reinstall --no-cache-dir \"git+https://github.com/briangallagher/sdk@training-hub\"\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ba46d-372f-49d0-a995-152167f30d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Prepare workspace directories\n",
    "base_dir = \"/opt/app-root/src\"\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "outputs_dir = os.path.join(base_dir, \"outputs\")\n",
    "ckpt_dir = os.path.join(base_dir, \"checkpoints\")\n",
    "\n",
    "for d in [data_dir, outputs_dir, ckpt_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "    os.chmod(d, 0o777)\n",
    "    print(f\"[PY] Ensured directory exists and writable: {d}\")\n",
    "\n",
    "dataset_path = os.path.join(data_dir, \"dataset.jsonl\")\n",
    "\n",
    "# Prepare workspace directories\n",
    "ds = load_dataset(\"Open-Orca/OpenOrca\", split=\"train\")\n",
    "\n",
    "def convert(example):\n",
    "    msgs = [{\"role\": \"system\", \"content\": example['system_prompt']}]\n",
    "    if example[\"question\"]:\n",
    "        msgs.append({\"role\": \"user\", \"content\": example[\"question\"]})\n",
    "    msgs.append({\"role\": \"assistant\", \"content\": example[\"response\"]})\n",
    "    return {\"messages\": msgs}\n",
    "\n",
    "sam = ds.shuffle(seed=42).select(range(1000))\n",
    "alp = sam.map(convert)\n",
    "alp.to_json(dataset_path, orient=\"records\", lines=True)\n",
    "print(f\"[PY] Finished writing dataset: {d}\")\n",
    "print(f\"[PY] Created dataset file: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9edb25-1b49-4843-9602-44b093bc3ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubeflow.trainer import TrainerClient, TrainingHubTrainer, TrainingHubAlgorithms\n",
    "from kubeflow_trainer_api import models\n",
    "\n",
    "client = TrainerClient()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b3b25-75f2-44ce-b7a7-da198ab206fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Needed to add cluster role binding to read the cluster scoped runtimes\n",
    "\n",
    "for runtime in client.list_runtimes():\n",
    "    if runtime.name == \"training-hub-sft\":\n",
    "        sft_runtime = runtime\n",
    "        print(\"Found runtime: \" + str(sft_runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4bf48-1ba1-42b4-80aa-c3be14d9bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"model_path\":\"Qwen/Qwen2.5-0.5B\",\n",
    "    \"data_path\": \"/opt/app-root/src/data/dataset.jsonl\",\n",
    "    \"ckpt_output_dir\": \"/opt/app-root/src/checkpoints\",\n",
    "    \"data_output_dir\": \"/opt/app-root/src/outputs\",\n",
    "    \"num_epochs\": 1,\n",
    "    \"effective_batch_size\": 128,\n",
    "    \"max_tokens_per_gpu\": 2048,\n",
    "    \"learning_rate\": 1e-05,\n",
    "    \"max_seq_len\": 512,\n",
    "    \"max_batch_len\": 512,\n",
    "    \"save_samples\": 0,\n",
    "    \"warmup_steps\": 100,\n",
    "    \"checkpoint_at_epoch\": True,\n",
    "    \"accelerate_full_state_at_epoch\": True,\n",
    "    \"rdzv_id\": 1,\n",
    "    \"disable_flash_attn\": True,\n",
    "    \"packing\": False,\n",
    "    \"enable_multipack\": False,\n",
    "    \"fp16\": True,\n",
    "    \"bf16\": False,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"distributed_training_framework\": \"fsdp\",\n",
    "    \"fsdp_sharding_strategy\": \"SHARD_GRAD_OP\",\n",
    "    \"disable_multipack\": True,\n",
    "    \"dtype\": \"float16\",\n",
    "    \"nproc_per_node\": 1,\n",
    "    \"nnodes\": 2,\n",
    "}\n",
    "\n",
    "# Kubernetes volumes and mounts (PVC example)\n",
    "volumes = [\n",
    "    models.IoK8sApiCoreV1Volume(\n",
    "        name=\"example\",\n",
    "        persistent_volume_claim=models.IoK8sApiCoreV1PersistentVolumeClaimVolumeSource(\n",
    "            claim_name=\"example\"\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "volume_mounts = [\n",
    "    models.IoK8sApiCoreV1VolumeMount(\n",
    "        name=\"example\",\n",
    "        mount_path=\"/opt/app-root/src/\",\n",
    "        read_only=False,\n",
    "    ),\n",
    "]\n",
    "\n",
    "job_name = client.train(\n",
    "    trainer=TrainingHubTrainer(\n",
    "        algorithm=TrainingHubAlgorithms.SFT,\n",
    "        func_args=args,\n",
    "        # packages_to_install=[\"training-hub\"],\n",
    "        volumes=volumes,\n",
    "        volume_mounts=volume_mounts\n",
    "    ),\n",
    "    runtime=sft_runtime,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13909e7a-38bd-4c3f-8589-3bc799ec08de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13637fd3-c8cf-4463-91df-878d078b1eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
